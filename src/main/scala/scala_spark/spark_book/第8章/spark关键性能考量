spark的特定行动操作所形成的步骤的集合被称为一个作业
在物理执行期间，RDD会被分为一系列的分区，每个分区都是整个数据的字迹
spark调度运行任务时，会为每个分区中的数据创建一个任务，此时spark会针对RDD直接自动推断出合适的并行度

并行度会从以下两个方面影响程序的性能：
    并行度过低时，spark会出现资源闲置的情况
    并行度过高时，每个分区的间接开销累计就会更大。

并行度调优：
    在数据混洗操作时，使用参数的方式为混洗后的RDD指定并行度
    对于已有的RDD，可以进行重新分区来获取合适的分区数目(repartition()会打乱数据重新分区，而coalesce()不会重新打乱分区)

序列化格式：
    spark在进行网络传输数据时，会将数据溢出到磁盘上，此时需要将数据在混洗操作时序列化为二进制格式，若是用默认的java序列化库效率较为地下，此时应该用Kryo序列化工具。

内存管理：
  内存用途：
    RDD存储，当调用RDD的persist和cache方法时，RDD的分区会被存储到缓存区中
    数据混洗与聚合的缓存区，存储聚合操作的中间结果。
    用户代码。


